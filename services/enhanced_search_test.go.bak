package services

import (
	"context"
	"semantic-text-processor/models"
	"testing"
	"time"
)

// Test suite for enhanced search functionality (Task 6)

func TestOptimizedSemanticSearch(t *testing.T) {
	// Setup test environment
	service := setupTestEnhancedSearchService(t)

	tests := []struct {
		name           string
		request        *models.OptimizedSearchRequest
		expectError    bool
		expectResults  bool
		expectCacheHit bool
	}{
		{
			name: "Valid semantic search",
			request: &models.OptimizedSearchRequest{
				Query:         "machine learning algorithms",
				Limit:         10,
				MinSimilarity: 0.7,
			},
			expectError:   false,
			expectResults: true,
		},
		{
			name: "Empty query",
			request: &models.OptimizedSearchRequest{
				Query: "",
				Limit: 10,
			},
			expectError:   false,
			expectResults: false,
		},
		{
			name: "Search with filters",
			request: &models.OptimizedSearchRequest{
				Query:  "data science",
				Limit:  5,
				Filters: map[string]interface{}{
					"text_id": "test-123",
				},
			},
			expectError:   false,
			expectResults: true,
		},
		{
			name: "Cached search",
			request: &models.OptimizedSearchRequest{
				Query:         "cached query test",
				Limit:         10,
				MinSimilarity: 0.6,
			},
			expectError:    false,
			expectResults:  true,
			expectCacheHit: true,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			ctx := context.Background()

			// For cache test, run query twice
			if tt.expectCacheHit {
				// First run to populate cache
				service.OptimizedSemanticSearch(ctx, tt.request)
			}

			// Main test run
			response, err := service.OptimizedSemanticSearch(ctx, tt.request)

			if tt.expectError && err == nil {
				t.Errorf("Expected error but got none")
			}
			if !tt.expectError && err != nil {
				t.Errorf("Unexpected error: %v", err)
			}

			if tt.expectResults && len(response.Results) == 0 {
				t.Errorf("Expected results but got none")
			}
			if !tt.expectResults && len(response.Results) > 0 {
				t.Errorf("Expected no results but got %d", len(response.Results))
			}

			if tt.expectCacheHit && !response.CacheHit {
				t.Errorf("Expected cache hit but got cache miss")
			}

			// Verify response structure
			if response.Duration <= 0 {
				t.Errorf("Expected positive duration")
			}
			if len(response.Optimizations) == 0 {
				t.Errorf("Expected optimization information")
			}
		})
	}
}

func TestHighPerformanceTagSearch(t *testing.T) {
	service := setupTestEnhancedSearchService(t)

	tests := []struct {
		name          string
		request       *models.TagSearchRequest
		expectError   bool
		expectResults bool
	}{
		{
			name: "Single tag search",
			request: &models.TagSearchRequest{
				Tags:  []string{"python"},
				Limit: 10,
			},
			expectError:   false,
			expectResults: true,
		},
		{
			name: "Multi-tag AND search",
			request: &models.TagSearchRequest{
				Tags:            []string{"python", "machine-learning"},
				CombinationMode: "AND",
				Limit:           15,
			},
			expectError:   false,
			expectResults: true,
		},
		{
			name: "Multi-tag OR search",
			request: &models.TagSearchRequest{
				Tags:            []string{"javascript", "nodejs"},
				CombinationMode: "OR",
				Limit:           20,
			},
			expectError:   false,
			expectResults: true,
		},
		{
			name: "Tag NOT search",
			request: &models.TagSearchRequest{
				Tags:            []string{"programming", "beginner"},
				CombinationMode: "NOT",
				Limit:           10,
			},
			expectError:   false,
			expectResults: true,
		},
		{
			name: "Empty tags",
			request: &models.TagSearchRequest{
				Tags:  []string{},
				Limit: 10,
			},
			expectError:   false,
			expectResults: false,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			ctx := context.Background()
			response, err := service.HighPerformanceTagSearch(ctx, tt.request)

			if tt.expectError && err == nil {
				t.Errorf("Expected error but got none")
			}
			if !tt.expectError && err != nil {
				t.Errorf("Unexpected error: %v", err)
			}

			if tt.expectResults && len(response.Results) == 0 {
				t.Errorf("Expected results but got none")
			}

			// Verify tag statistics are included
			if len(response.TagStats) == 0 && len(tt.request.Tags) > 0 {
				t.Errorf("Expected tag statistics")
			}

			// Verify optimizations are reported
			if len(response.Optimizations) == 0 {
				t.Errorf("Expected optimization information")
			}
		})
	}
}

func TestFullTextSearchOptimized(t *testing.T) {
	service := setupTestEnhancedSearchService(t)

	tests := []struct {
		name          string
		request       *models.FullTextRequest
		expectError   bool
		expectResults bool
	}{
		{
			name: "Basic full-text search",
			request: &models.FullTextRequest{
				Query: "artificial intelligence neural networks",
				Limit: 10,
			},
			expectError:   false,
			expectResults: true,
		},
		{
			name: "Search with snippets",
			request: &models.FullTextRequest{
				Query:           "database optimization",
				Limit:           15,
				IncludeSnippets: true,
			},
			expectError:   false,
			expectResults: true,
		},
		{
			name: "Search with highlights",
			request: &models.FullTextRequest{
				Query:             "web development",
				Limit:             20,
				IncludeHighlights: true,
			},
			expectError:   false,
			expectResults: true,
		},
		{
			name: "BM25 ranking",
			request: &models.FullTextRequest{
				Query:       "search algorithms",
				Limit:       10,
				RankingMode: "bm25",
			},
			expectError:   false,
			expectResults: true,
		},
		{
			name: "Empty query",
			request: &models.FullTextRequest{
				Query: "",
				Limit: 10,
			},
			expectError:   false,
			expectResults: false,
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			ctx := context.Background()
			response, err := service.FullTextSearchOptimized(ctx, tt.request)

			if tt.expectError && err == nil {
				t.Errorf("Expected error but got none")
			}
			if !tt.expectError && err != nil {
				t.Errorf("Unexpected error: %v", err)
			}

			if tt.expectResults && len(response.Results) == 0 {
				t.Errorf("Expected results but got none")
			}

			// Verify suggestions are provided
			if len(response.Suggestions) == 0 && tt.request.Query != "" {
				t.Errorf("Expected search suggestions")
			}

			// Verify query analysis
			if response.QueryAnalysis.OriginalQuery == "" && tt.request.Query != "" {
				t.Errorf("Expected query analysis")
			}

			// Check optimizations
			if len(response.Optimizations) == 0 {
				t.Errorf("Expected optimization information")
			}
		})
	}
}

func TestSearchBenchmarks(t *testing.T) {
	service := setupTestEnhancedSearchService(t)

	ctx := context.Background()
	results, err := service.RunSearchBenchmarks(ctx)

	if err != nil {
		t.Fatalf("Benchmark failed: %v", err)
	}

	// Verify benchmark results structure
	if results.OverallScore <= 0 {
		t.Errorf("Expected positive overall score, got %f", results.OverallScore)
	}

	if results.SemanticSearch.AverageResponseTime <= 0 {
		t.Errorf("Expected positive semantic search response time")
	}

	if results.TagSearch.ThroughputQPS <= 0 {
		t.Errorf("Expected positive tag search throughput")
	}

	if results.FullTextSearch.SuccessRate <= 0 {
		t.Errorf("Expected positive full-text search success rate")
	}

	if results.CachePerformance.OverallHitRate < 0 || results.CachePerformance.OverallHitRate > 1 {
		t.Errorf("Invalid cache hit rate: %f", results.CachePerformance.OverallHitRate)
	}
}

func TestCacheWarmingAndStatistics(t *testing.T) {
	service := setupTestEnhancedSearchService(t)
	ctx := context.Background()

	// Test cache warming
	patterns := []string{"popular_searches", "recent_queries"}
	err := service.WarmSearchCache(ctx, patterns)
	if err != nil {
		t.Fatalf("Cache warming failed: %v", err)
	}

	// Test statistics retrieval
	stats, err := service.GetSearchStatistics(ctx)
	if err != nil {
		t.Fatalf("Failed to get search statistics: %v", err)
	}

	// Verify statistics structure
	if stats.TotalSearches < 0 {
		t.Errorf("Invalid total searches count: %d", stats.TotalSearches)
	}

	if stats.CacheHitRate < 0 || stats.CacheHitRate > 1 {
		t.Errorf("Invalid cache hit rate: %f", stats.CacheHitRate)
	}

	if stats.PerformanceMetrics == nil {
		t.Errorf("Expected performance metrics")
	}
}

func TestVectorSimilarityCache(t *testing.T) {
	cache := NewVectorSimilarityCache(100, 10*time.Minute)

	// Test cache set and get
	key := "test-key"
	result := &VectorSearchResult{
		Results:    []models.SearchResult{{ChunkID: "chunk-1", Content: "test content"}},
		TotalCount: 1,
	}

	cache.Set(key, result)

	retrieved, found := cache.Get(key)
	if !found {
		t.Errorf("Expected to find cached result")
	}

	if retrieved.TotalCount != result.TotalCount {
		t.Errorf("Retrieved result doesn't match original")
	}

	// Test cache miss
	_, found = cache.Get("non-existent-key")
	if found {
		t.Errorf("Expected cache miss for non-existent key")
	}
}

func TestTagStatisticsCache(t *testing.T) {
	cache := NewTagStatisticsCache(1000, 10*time.Minute)

	// Test statistics update and retrieval
	tagStats := map[string]int{
		"python":     100,
		"javascript": 80,
		"golang":     60,
	}
	popularTags := []string{"python", "javascript", "golang"}

	cache.UpdateStats(tagStats, popularTags)

	// Test stats retrieval
	tags := []string{"python", "javascript"}
	stats, found := cache.GetStats(tags)
	if !found {
		t.Errorf("Expected to find tag statistics")
	}

	if stats["python"] != 100 {
		t.Errorf("Expected python count to be 100, got %d", stats["python"])
	}

	// Test popular tags
	popular := cache.GetPopularTags(2)
	if len(popular) != 2 {
		t.Errorf("Expected 2 popular tags, got %d", len(popular))
	}
}

func TestFullTextIndexCache(t *testing.T) {
	cache := NewFullTextIndexCache(nil)

	// Test cache operations
	key := "fulltext-test"
	entry := &FullTextCacheEntry{
		Results: []models.FullTextResult{
			{ChunkID: "chunk-1", Content: "test content", RelevanceScore: 0.8},
		},
		Suggestions: []string{"suggestion1", "suggestion2"},
		TotalCount:  1,
	}

	cache.Set(key, entry)

	retrieved, found := cache.Get(key)
	if !found {
		t.Errorf("Expected to find cached entry")
	}

	if len(retrieved.Results) != 1 {
		t.Errorf("Expected 1 result, got %d", len(retrieved.Results))
	}

	if len(retrieved.Suggestions) != 2 {
		t.Errorf("Expected 2 suggestions, got %d", len(retrieved.Suggestions))
	}
}

func TestSearchOptimizationHelpers(t *testing.T) {
	service := setupTestEnhancedSearchService(t)

	// Test tag search order optimization
	tags := []string{"common", "rare", "medium"}
	tagStats := map[string]int{
		"common": 1000,
		"rare":   10,
		"medium": 100,
	}

	optimized := service.optimizeTagSearchOrder(tags, tagStats)

	// Should order by frequency (ascending for AND operations)
	if optimized[0] != "rare" {
		t.Errorf("Expected 'rare' to be first, got %s", optimized[0])
	}

	// Test query preprocessing
	query := "The quick brown fox jumps over the lazy dog"
	processed := service.preprocessTextQuery(query)

	if processed == query {
		t.Errorf("Expected query to be processed")
	}

	// Test relevance calculation
	chunk := &models.UnifiedChunkRecord{
		ChunkID:   "test-chunk",
		Content:   "machine learning algorithms",
		UpdatedAt: time.Now(),
	}

	relevance := service.calculateRelevanceScore(chunk, "machine learning")
	if relevance <= 0 {
		t.Errorf("Expected positive relevance score, got %f", relevance)
	}
}

// Helper function to setup test service
func setupTestEnhancedSearchService(t *testing.T) EnhancedSearchService {
	// Create mock dependencies
	mockUnifiedService := &MockUnifiedChunkService{}
	mockEmbeddingService := &MockEmbeddingService{}
	mockSearchCache := &MockSearchCacheService{}
	mockMonitor := &MockQueryPerformanceMonitor{}

	config := &EnhancedSearchConfig{
		VectorBatchSize:    50,
		VectorCacheEnabled: true,
		VectorCacheTTL:     10 * time.Minute,
		PreloadEnabled:     false, // Disable for tests
		BenchmarkInterval:  0,     // Disable for tests
	}

	return NewEnhancedSearchService(
		mockUnifiedService,
		mockEmbeddingService,
		mockSearchCache,
		mockMonitor,
		&MockLogger{},
		config,
	)
}

// Mock implementations for testing

type MockUnifiedChunkService struct{}

func (m *MockUnifiedChunkService) OptimizedVectorSearch(ctx context.Context, query *models.UnifiedSearchQuery) (*models.SearchResult, error) {
	return &models.SearchResult{
		Chunks: []*models.UnifiedChunkRecord{
			{
				ChunkID:         "chunk-1",
				Content:         "test content",
				SimilarityScore: 0.85,
				Tags:            []string{"test"},
				UpdatedAt:       time.Now(),
			},
		},
		TotalCount: 1,
	}, nil
}

func (m *MockUnifiedChunkService) SearchByTag(ctx context.Context, tag string, limit int) ([]models.TaggedChunk, error) {
	return []models.TaggedChunk{
		{
			ChunkID: "chunk-1",
			Content: "test content",
			Tags:    []string{tag},
			TagRelevance: map[string]float64{
				tag: 0.9,
			},
			CreatedAt: time.Now(),
			UpdatedAt: time.Now(),
		},
	}, nil
}

func (m *MockUnifiedChunkService) FullTextSearch(ctx context.Context, query *models.FullTextSearchQuery) ([]models.FullTextResult, error) {
	return []models.FullTextResult{
		{
			ChunkID:        "chunk-1",
			Content:        "test content",
			RelevanceScore: 0.8,
			BM25Score:      0.75,
			MatchedTerms:   []string{"test"},
		},
	}, nil
}

func (m *MockUnifiedChunkService) GetTagStatistics(ctx context.Context) (map[string]int, error) {
	return map[string]int{
		"python":     100,
		"javascript": 80,
		"golang":     60,
	}, nil
}

type MockEmbeddingService struct{}

func (m *MockEmbeddingService) GenerateEmbedding(ctx context.Context, text string) ([]float64, error) {
	// Return a mock embedding vector
	return []float64{0.1, 0.2, 0.3, 0.4, 0.5}, nil
}

type MockSearchCacheService struct{}

func (m *MockSearchCacheService) GetCachedSearch(ctx context.Context, queryParams map[string]interface{}) (*models.SearchCacheEntry, error) {
	return nil, nil // Always cache miss for simplicity
}

func (m *MockSearchCacheService) SetCachedSearch(ctx context.Context, queryParams map[string]interface{}, chunkIDs []string, ttl time.Duration) error {
	return nil
}

func (m *MockSearchCacheService) InvalidateSearchCache(ctx context.Context, patterns []string) error {
	return nil
}

func (m *MockSearchCacheService) CleanupExpiredEntries(ctx context.Context) (int, error) {
	return 0, nil
}

func (m *MockSearchCacheService) GetCacheStats(ctx context.Context) (*SearchCacheStats, error) {
	return &SearchCacheStats{
		TotalEntries: 100,
		HitRate:      0.75,
	}, nil
}

func (m *MockSearchCacheService) GetOptimizationSuggestions(ctx context.Context) ([]OptimizationSuggestion, error) {
	return []OptimizationSuggestion{}, nil
}

func (m *MockSearchCacheService) UpdateHitCount(ctx context.Context, searchHash string) error {
	return nil
}

type MockQueryPerformanceMonitor struct{}

func (m *MockQueryPerformanceMonitor) RecordQuery(queryType string, duration time.Duration, resultCount int) {}

type MockLogger struct{}

func (m *MockLogger) Printf(format string, v ...interface{}) {}

// Benchmark tests

func BenchmarkOptimizedSemanticSearch(b *testing.B) {
	service := setupTestEnhancedSearchService(nil)
	ctx := context.Background()
	req := &models.OptimizedSearchRequest{
		Query: "machine learning algorithms",
		Limit: 10,
	}

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		service.OptimizedSemanticSearch(ctx, req)
	}
}

func BenchmarkHighPerformanceTagSearch(b *testing.B) {
	service := setupTestEnhancedSearchService(nil)
	ctx := context.Background()
	req := &models.TagSearchRequest{
		Tags:  []string{"python", "programming"},
		Limit: 10,
	}

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		service.HighPerformanceTagSearch(ctx, req)
	}
}

func BenchmarkFullTextSearchOptimized(b *testing.B) {
	service := setupTestEnhancedSearchService(nil)
	ctx := context.Background()
	req := &models.FullTextRequest{
		Query: "database optimization performance",
		Limit: 10,
	}

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		service.FullTextSearchOptimized(ctx, req)
	}
}

func BenchmarkVectorSimilarityCache(b *testing.B) {
	cache := NewVectorSimilarityCache(1000, 10*time.Minute)
	result := &VectorSearchResult{
		Results:    []models.SearchResult{{ChunkID: "chunk-1"}},
		TotalCount: 1,
	}

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		key := fmt.Sprintf("key-%d", i%100)
		cache.Set(key, result)
		cache.Get(key)
	}
}