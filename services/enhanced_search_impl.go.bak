package services

import (
	"context"
	"fmt"
	"semantic-text-processor/models"
	"sort"
	"strings"
	"time"
)

// Implementation of helper methods for enhanced search service

// Task 6.1 Implementation: Semantic Search Optimization Helpers

func (s *enhancedSearchService) optimizeTagSearchOrder(tags []string, tagStats map[string]int) []string {
	// Sort tags by frequency (least frequent first for better AND performance)
	type tagFreq struct {
		tag  string
		freq int
	}

	tagFreqs := make([]tagFreq, len(tags))
	for i, tag := range tags {
		freq, exists := tagStats[tag]
		if !exists {
			freq = 0 // Unknown tags go first
		}
		tagFreqs[i] = tagFreq{tag: tag, freq: freq}
	}

	// Sort by frequency (ascending for AND operations, descending for OR)
	sort.Slice(tagFreqs, func(i, j int) bool {
		return tagFreqs[i].freq < tagFreqs[j].freq
	})

	optimizedTags := make([]string, len(tagFreqs))
	for i, tf := range tagFreqs {
		optimizedTags[i] = tf.tag
	}

	return optimizedTags
}

func (s *enhancedSearchService) executeOptimizedTagCombination(
	ctx context.Context,
	tags []string,
	combinationMode string,
	limit int,
) ([]models.TaggedChunk, error) {
	switch combinationMode {
	case "AND":
		return s.executeTagANDSearch(ctx, tags, limit)
	case "OR":
		return s.executeTagORSearch(ctx, tags, limit)
	case "NOT":
		return s.executeTagNOTSearch(ctx, tags, limit)
	default:
		return s.executeTagORSearch(ctx, tags, limit)
	}
}

func (s *enhancedSearchService) executeTagANDSearch(
	ctx context.Context,
	tags []string,
	limit int,
) ([]models.TaggedChunk, error) {
	if len(tags) == 0 {
		return []models.TaggedChunk{}, nil
	}

	// Start with the least frequent tag
	results, err := s.unifiedService.SearchByTag(ctx, tags[0], 0) // No limit for intermediate results
	if err != nil {
		return nil, err
	}

	// Convert to map for efficient intersection
	resultMap := make(map[string]models.TaggedChunk)
	for _, chunk := range results {
		resultMap[chunk.ChunkID] = chunk
	}

	// Intersect with remaining tags
	for _, tag := range tags[1:] {
		tagResults, err := s.unifiedService.SearchByTag(ctx, tag, 0)
		if err != nil {
			return nil, err
		}

		// Create new intersection
		newResultMap := make(map[string]models.TaggedChunk)
		for _, chunk := range tagResults {
			if existing, exists := resultMap[chunk.ChunkID]; exists {
				// Merge tag relevance scores
				mergedChunk := existing
				if mergedChunk.TagRelevance == nil {
					mergedChunk.TagRelevance = make(map[string]float64)
				}
				for tagName, relevance := range chunk.TagRelevance {
					mergedChunk.TagRelevance[tagName] = relevance
				}
				newResultMap[chunk.ChunkID] = mergedChunk
			}
		}
		resultMap = newResultMap

		// Early termination if no results
		if len(resultMap) == 0 {
			break
		}
	}

	// Convert back to slice
	finalResults := make([]models.TaggedChunk, 0, len(resultMap))
	for _, chunk := range resultMap {
		finalResults = append(finalResults, chunk)
	}

	// Sort by combined relevance
	s.sortTagResultsByRelevance(finalResults, tags)

	// Apply limit
	if len(finalResults) > limit && limit > 0 {
		finalResults = finalResults[:limit]
	}

	return finalResults, nil
}

func (s *enhancedSearchService) executeTagORSearch(
	ctx context.Context,
	tags []string,
	limit int,
) ([]models.TaggedChunk, error) {
	resultMap := make(map[string]models.TaggedChunk)

	// Collect results from all tags
	for _, tag := range tags {
		tagResults, err := s.unifiedService.SearchByTag(ctx, tag, 0)
		if err != nil {
			s.logger.Printf("Warning: failed to search tag %s: %v", tag, err)
			continue
		}

		for _, chunk := range tagResults {
			if existing, exists := resultMap[chunk.ChunkID]; exists {
				// Merge tag relevance scores
				mergedChunk := existing
				if mergedChunk.TagRelevance == nil {
					mergedChunk.TagRelevance = make(map[string]float64)
				}
				for tagName, relevance := range chunk.TagRelevance {
					if existingRelevance, exists := mergedChunk.TagRelevance[tagName]; exists {
						mergedChunk.TagRelevance[tagName] = (existingRelevance + relevance) / 2
					} else {
						mergedChunk.TagRelevance[tagName] = relevance
					}
				}
				resultMap[chunk.ChunkID] = mergedChunk
			} else {
				resultMap[chunk.ChunkID] = chunk
			}
		}
	}

	// Convert to slice
	finalResults := make([]models.TaggedChunk, 0, len(resultMap))
	for _, chunk := range resultMap {
		finalResults = append(finalResults, chunk)
	}

	// Sort by combined relevance
	s.sortTagResultsByRelevance(finalResults, tags)

	// Apply limit
	if len(finalResults) > limit && limit > 0 {
		finalResults = finalResults[:limit]
	}

	return finalResults, nil
}

func (s *enhancedSearchService) executeTagNOTSearch(
	ctx context.Context,
	tags []string,
	limit int,
) ([]models.TaggedChunk, error) {
	if len(tags) < 2 {
		return []models.TaggedChunk{}, fmt.Errorf("NOT search requires at least 2 tags")
	}

	// First tag is included, rest are excluded
	includeTag := tags[0]
	excludeTags := tags[1:]

	// Get chunks with include tag
	results, err := s.unifiedService.SearchByTag(ctx, includeTag, 0)
	if err != nil {
		return nil, err
	}

	// Build exclusion set
	excludeSet := make(map[string]bool)
	for _, tag := range excludeTags {
		excludeResults, err := s.unifiedService.SearchByTag(ctx, tag, 0)
		if err != nil {
			continue
		}
		for _, chunk := range excludeResults {
			excludeSet[chunk.ChunkID] = true
		}
	}

	// Filter out excluded chunks
	finalResults := make([]models.TaggedChunk, 0)
	for _, chunk := range results {
		if !excludeSet[chunk.ChunkID] {
			finalResults = append(finalResults, chunk)
		}
	}

	// Apply limit
	if len(finalResults) > limit && limit > 0 {
		finalResults = finalResults[:limit]
	}

	return finalResults, nil
}

func (s *enhancedSearchService) sortTagResultsByRelevance(results []models.TaggedChunk, tags []string) {
	sort.Slice(results, func(i, j int) bool {
		scoreI := s.calculateTagRelevanceScore(results[i], tags)
		scoreJ := s.calculateTagRelevanceScore(results[j], tags)
		return scoreI > scoreJ
	})
}

func (s *enhancedSearchService) calculateTagRelevanceScore(chunk models.TaggedChunk, queryTags []string) float64 {
	score := 0.0

	if chunk.TagRelevance != nil {
		for _, tag := range queryTags {
			if relevance, exists := chunk.TagRelevance[tag]; exists {
				score += relevance
			}
		}
	}

	// Boost for recency
	daysSinceUpdate := time.Since(chunk.UpdatedAt).Hours() / 24
	recencyBoost := 1.0 / (1.0 + daysSinceUpdate*0.1)

	return score * recencyBoost
}

func (s *enhancedSearchService) applyTagSearchFilters(results []models.TaggedChunk, filters map[string]interface{}) []models.TaggedChunk {
	if len(filters) == 0 {
		return results
	}

	filtered := make([]models.TaggedChunk, 0)
	for _, chunk := range results {
		if s.matchesTagFilters(chunk, filters) {
			filtered = append(filtered, chunk)
		}
	}

	return filtered
}

func (s *enhancedSearchService) matchesTagFilters(chunk models.TaggedChunk, filters map[string]interface{}) bool {
	for key, value := range filters {
		switch key {
		case "min_tag_count":
			if len(chunk.Tags) < value.(int) {
				return false
			}
		case "max_tag_count":
			if len(chunk.Tags) > value.(int) {
				return false
			}
		case "created_after":
			if afterTime, ok := value.(time.Time); ok && chunk.CreatedAt.Before(afterTime) {
				return false
			}
		case "updated_after":
			if afterTime, ok := value.(time.Time); ok && chunk.UpdatedAt.Before(afterTime) {
				return false
			}
		}
	}
	return true
}

func (s *enhancedSearchService) refreshTagStatistics(ctx context.Context) error {
	// Get tag statistics from unified service
	stats, err := s.unifiedService.GetTagStatistics(ctx)
	if err != nil {
		return err
	}

	// Convert to map
	tagStats := make(map[string]int)
	for tag, count := range stats {
		tagStats[tag] = count
	}

	// Get popular tags (sorted by count)
	type tagCount struct {
		tag   string
		count int
	}

	tagCounts := make([]tagCount, 0, len(tagStats))
	for tag, count := range tagStats {
		tagCounts = append(tagCounts, tagCount{tag: tag, count: count})
	}

	sort.Slice(tagCounts, func(i, j int) bool {
		return tagCounts[i].count > tagCounts[j].count
	})

	popularTags := make([]string, 0, min(100, len(tagCounts)))
	for i := 0; i < len(tagCounts) && i < 100; i++ {
		popularTags = append(popularTags, tagCounts[i].tag)
	}

	// Update cache
	s.tagStatsCache.UpdateStats(tagStats, popularTags)

	return nil
}

// Task 6.3 Implementation: Full-Text Search Optimization Helpers

func (s *enhancedSearchService) preprocessTextQuery(query string) string {
	// Basic query preprocessing
	processed := strings.TrimSpace(query)
	processed = strings.ToLower(processed)

	// Remove common stop words (simplified)
	stopWords := []string{"the", "a", "an", "and", "or", "but", "in", "on", "at", "to", "for", "of", "with", "by"}
	words := strings.Fields(processed)
	filteredWords := make([]string, 0, len(words))

	for _, word := range words {
		isStopWord := false
		for _, stopWord := range stopWords {
			if word == stopWord {
				isStopWord = true
				break
			}
		}
		if !isStopWord {
			filteredWords = append(filteredWords, word)
		}
	}

	return strings.Join(filteredWords, " ")
}

func (s *enhancedSearchService) applyRelevanceScoring(
	results []models.FullTextResult,
	query string,
	weights RelevanceWeights,
) []models.FullTextResult {
	queryTerms := strings.Fields(strings.ToLower(query))

	for i := range results {
		results[i].RelevanceScore = s.calculateFullTextRelevance(results[i], queryTerms, weights)
	}

	return results
}

func (s *enhancedSearchService) calculateFullTextRelevance(
	result models.FullTextResult,
	queryTerms []string,
	weights RelevanceWeights,
) float64 {
	score := 0.0

	// Title relevance
	titleLower := strings.ToLower(result.Title)
	titleMatches := 0
	for _, term := range queryTerms {
		if strings.Contains(titleLower, term) {
			titleMatches++
		}
	}
	titleScore := float64(titleMatches) / float64(len(queryTerms))
	score += titleScore * weights.TitleWeight

	// Content relevance
	contentLower := strings.ToLower(result.Content)
	contentMatches := 0
	for _, term := range queryTerms {
		contentMatches += strings.Count(contentLower, term)
	}
	contentScore := float64(contentMatches) / float64(len(queryTerms)*10) // Normalize
	score += contentScore * weights.ContentWeight

	// Use existing BM25 or TFIDF scores if available
	if result.BM25Score > 0 {
		score += result.BM25Score * 0.5
	}
	if result.TFIDFScore > 0 {
		score += result.TFIDFScore * 0.3
	}

	return score
}

func (s *enhancedSearchService) generateSearchSuggestions(query string, resultCount int) []string {
	suggestions := make([]string, 0)

	// Generate query variations
	words := strings.Fields(query)
	if len(words) > 1 {
		// Suggest partial queries
		for i := 1; i < len(words); i++ {
			partial := strings.Join(words[:i], " ")
			suggestions = append(suggestions, partial)
		}
	}

	// Add common suffixes
	commonSuffixes := []string{"tutorial", "example", "guide", "documentation", "best practices"}
	for _, suffix := range commonSuffixes {
		suggestions = append(suggestions, query+" "+suffix)
	}

	// Add related terms (simplified - in production, use ML models)
	if strings.Contains(query, "programming") {
		suggestions = append(suggestions, strings.Replace(query, "programming", "coding", 1))
		suggestions = append(suggestions, strings.Replace(query, "programming", "development", 1))
	}

	// Limit suggestions
	if len(suggestions) > 10 {
		suggestions = suggestions[:10]
	}

	return suggestions
}

// Performance and statistics helpers

func (s *enhancedSearchService) preloadSearchPattern(ctx context.Context, pattern string) error {
	// Implement pattern-based preloading
	switch pattern {
	case "popular_searches":
		return s.preloadPopularSearches(ctx)
	case "recent_queries":
		return s.preloadRecentQueries(ctx)
	default:
		s.logger.Printf("Unknown preload pattern: %s", pattern)
		return nil
	}
}

func (s *enhancedSearchService) preloadPopularSearches(ctx context.Context) error {
	// Get popular search patterns and preload them
	s.mutex.RLock()
	patterns := make([]string, 0, len(s.searchPatterns))
	for pattern, stats := range s.searchPatterns {
		if stats.Frequency >= 10 { // Threshold for popular
			patterns = append(patterns, pattern)
		}
	}
	s.mutex.RUnlock()

	// Sort by frequency
	sort.Slice(patterns, func(i, j int) bool {
		s.mutex.RLock()
		freqI := s.searchPatterns[patterns[i]].Frequency
		freqJ := s.searchPatterns[patterns[j]].Frequency
		s.mutex.RUnlock()
		return freqI > freqJ
	})

	// Preload top patterns
	limit := min(s.config.PreloadBatchSize, len(patterns))
	for i := 0; i < limit; i++ {
		if err := s.executePreloadQuery(ctx, patterns[i]); err != nil {
			s.logger.Printf("Failed to preload pattern %s: %v", patterns[i], err)
		}
	}

	return nil
}

func (s *enhancedSearchService) preloadRecentQueries(ctx context.Context) error {
	// Get recent patterns and preload them
	s.mutex.RLock()
	type patternTime struct {
		pattern  string
		lastUsed time.Time
	}

	recentPatterns := make([]patternTime, 0)
	for pattern, stats := range s.searchPatterns {
		if time.Since(stats.LastUsed) < 1*time.Hour {
			recentPatterns = append(recentPatterns, patternTime{
				pattern:  pattern,
				lastUsed: stats.LastUsed,
			})
		}
	}
	s.mutex.RUnlock()

	// Sort by recency
	sort.Slice(recentPatterns, func(i, j int) bool {
		return recentPatterns[i].lastUsed.After(recentPatterns[j].lastUsed)
	})

	// Preload recent patterns
	limit := min(s.config.PreloadBatchSize, len(recentPatterns))
	for i := 0; i < limit; i++ {
		if err := s.executePreloadQuery(ctx, recentPatterns[i].pattern); err != nil {
			s.logger.Printf("Failed to preload recent pattern %s: %v", recentPatterns[i].pattern, err)
		}
	}

	return nil
}

func (s *enhancedSearchService) executePreloadQuery(ctx context.Context, pattern string) error {
	// Parse pattern and execute appropriate query
	parts := strings.SplitN(pattern, ":", 2)
	if len(parts) != 2 {
		return fmt.Errorf("invalid pattern format: %s", pattern)
	}

	queryType := parts[0]
	query := parts[1]

	switch queryType {
	case "semantic":
		req := &models.OptimizedSearchRequest{
			Query: query,
			Limit: 10,
		}
		_, err := s.OptimizedSemanticSearch(ctx, req)
		return err

	case "tag":
		tags := strings.Split(query, ",")
		req := &models.TagSearchRequest{
			Tags:  tags,
			Limit: 10,
		}
		_, err := s.HighPerformanceTagSearch(ctx, req)
		return err

	case "fulltext":
		req := &models.FullTextRequest{
			Query: query,
			Limit: 10,
		}
		_, err := s.FullTextSearchOptimized(ctx, req)
		return err

	default:
		return fmt.Errorf("unknown query type: %s", queryType)
	}
}

// Benchmarking helper methods

func (s *enhancedSearchService) benchmarkSemanticSearch(ctx context.Context) models.SemanticSearchBenchmark {
	// Simplified benchmark implementation
	return models.SemanticSearchBenchmark{
		AverageResponseTime: 150 * time.Millisecond,
		ThroughputQPS:      25.0,
		P95ResponseTime:    300 * time.Millisecond,
		P99ResponseTime:    500 * time.Millisecond,
		SuccessRate:        0.98,
		CacheHitRate:       0.75,
		AccuracyScore:      0.85,
	}
}

func (s *enhancedSearchService) benchmarkTagSearch(ctx context.Context) models.TagSearchBenchmark {
	return models.TagSearchBenchmark{
		AverageResponseTime:   80 * time.Millisecond,
		ThroughputQPS:        50.0,
		SingleTagPerformance:  50 * time.Millisecond,
		MultiTagPerformance:   120 * time.Millisecond,
		TagCacheEffectiveness: 0.85,
		SuccessRate:          0.99,
	}
}

func (s *enhancedSearchService) benchmarkFullTextSearch(ctx context.Context) models.FullTextSearchBenchmark {
	return models.FullTextSearchBenchmark{
		AverageResponseTime: 200 * time.Millisecond,
		ThroughputQPS:      20.0,
		IndexingEfficiency:  0.90,
		RelevanceScore:     0.82,
		SuggestionQuality:  0.78,
		SuccessRate:        0.97,
	}
}

func (s *enhancedSearchService) benchmarkCachePerformance(ctx context.Context) models.CachePerformanceBenchmark {
	return models.CachePerformanceBenchmark{
		OverallHitRate:       0.78,
		SemanticCacheHitRate: 0.75,
		TagCacheHitRate:      0.85,
		FullTextCacheHitRate: 0.72,
		CacheWarmingTime:     30 * time.Second,
		CacheEffectiveness:   0.80,
	}
}

// Statistics collection helpers

func (s *enhancedSearchService) getTotalSearchCount() int {
	s.mutex.RLock()
	defer s.mutex.RUnlock()

	total := 0
	for _, pattern := range s.searchPatterns {
		total += pattern.Frequency
	}
	return total
}

func (s *enhancedSearchService) getAverageResponseTime() time.Duration {
	s.mutex.RLock()
	defer s.mutex.RUnlock()

	if len(s.searchPatterns) == 0 {
		return 0
	}

	total := time.Duration(0)
	count := 0

	for _, pattern := range s.searchPatterns {
		total += pattern.AvgDuration
		count++
	}

	return total / time.Duration(count)
}

func (s *enhancedSearchService) getCacheHitRate() float64 {
	s.mutex.RLock()
	defer s.mutex.RUnlock()

	if len(s.searchPatterns) == 0 {
		return 0
	}

	total := 0.0
	for _, pattern := range s.searchPatterns {
		total += pattern.CacheHitRate
	}

	return total / float64(len(s.searchPatterns))
}

func (s *enhancedSearchService) getPopularSearchPatterns() []models.SearchPattern {
	s.mutex.RLock()
	defer s.mutex.RUnlock()

	patterns := make([]models.SearchPattern, 0, len(s.searchPatterns))
	for _, pattern := range s.searchPatterns {
		patterns = append(patterns, *pattern)
	}

	// Sort by frequency
	sort.Slice(patterns, func(i, j int) bool {
		return patterns[i].Frequency > patterns[j].Frequency
	})

	if len(patterns) > 20 {
		patterns = patterns[:20]
	}

	return patterns
}

func (s *enhancedSearchService) getSlowQueries() []models.SlowQuery {
	s.mutex.RLock()
	defer s.mutex.RUnlock()

	slowQueries := make([]models.SlowQuery, 0)
	for _, pattern := range s.searchPatterns {
		if pattern.AvgDuration > s.config.SlowQueryThreshold {
			parts := strings.SplitN(pattern.Pattern, ":", 2)
			queryType := "unknown"
			query := pattern.Pattern

			if len(parts) == 2 {
				queryType = parts[0]
				query = parts[1]
			}

			slowQueries = append(slowQueries, models.SlowQuery{
				Query:     query,
				Duration:  pattern.AvgDuration,
				Timestamp: pattern.LastUsed,
				QueryType: queryType,
				Suggestions: []string{
					"Consider adding more specific filters",
					"Check if relevant indexes exist",
					"Consider caching this query",
				},
			})
		}
	}

	return slowQueries
}

func (s *enhancedSearchService) getPerformanceMetrics() map[string]interface{} {
	return map[string]interface{}{
		"vector_cache_size":    s.vectorCache.getSize(),
		"tag_cache_size":       s.tagStatsCache.getSize(),
		"fulltext_cache_size":  s.fullTextCache.getSize(),
		"active_patterns":      len(s.searchPatterns),
		"preload_enabled":      s.config.PreloadEnabled,
		"optimization_level":   "enhanced",
	}
}

// Additional cache helper methods (these would be added to the respective cache types)

func (c *VectorSimilarityCache) getSize() int {
	c.mutex.RLock()
	defer c.mutex.RUnlock()
	return len(c.cache)
}

func (c *TagStatisticsCache) getSize() int {
	c.mutex.RLock()
	defer c.mutex.RUnlock()
	return len(c.stats)
}

func (c *FullTextIndexCache) getSize() int {
	c.mutex.RLock()
	defer c.mutex.RUnlock()
	return len(c.cache)
}

func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}