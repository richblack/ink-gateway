package handlers

import (
	"encoding/json"
	"log"
	"net/http"
	"semantic-text-processor/models"
	"semantic-text-processor/services"
	"strconv"
	"time"

	"github.com/gorilla/mux"
)

// EnhancedSearchHandler provides optimized search endpoints for Task 6
type EnhancedSearchHandler struct {
	enhancedService    services.EnhancedSearchService
	performanceMonitor *PerformanceMonitor
	logger             *log.Logger
}

// NewEnhancedSearchHandler creates a new enhanced search handler
func NewEnhancedSearchHandler(
	enhancedService services.EnhancedSearchService,
	logger *log.Logger,
	slowQueryThreshold time.Duration,
	metricsEnabled bool,
) *EnhancedSearchHandler {
	return &EnhancedSearchHandler{
		enhancedService:    enhancedService,
		performanceMonitor: NewPerformanceMonitor(slowQueryThreshold, logger, metricsEnabled),
		logger:             logger,
	}
}

// OptimizedSemanticSearch handles POST /api/v1/search/semantic/optimized
func (h *EnhancedSearchHandler) OptimizedSemanticSearch(w http.ResponseWriter, r *http.Request) {
	h.performanceMonitor.MonitoredHTTPOperation("optimized_semantic_search", w, func() (int, error) {
		var req models.OptimizedSearchRequest
		if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
			writeErrorResponse(w, http.StatusBadRequest, "invalid request body", err.Error())
			return http.StatusBadRequest, err
		}

		// Validate request
		if req.Query == "" {
			writeErrorResponse(w, http.StatusBadRequest, "query is required", "")
			return http.StatusBadRequest, nil
		}

		// Set defaults
		if req.Limit <= 0 {
			req.Limit = 10
		}
		if req.MinSimilarity <= 0 {
			req.MinSimilarity = 0.7
		}

		// Execute optimized semantic search
		response, err := h.enhancedService.OptimizedSemanticSearch(r.Context(), &req)
		if err != nil {
			writeErrorResponse(w, http.StatusInternalServerError, "optimized semantic search failed", err.Error())
			return http.StatusInternalServerError, err
		}

		// Add performance headers
		if response.CacheHit {
			w.Header().Set("X-Cache", "HIT")
		} else {
			w.Header().Set("X-Cache", "MISS")
		}
		w.Header().Set("X-Response-Time", response.Duration.String())
		w.Header().Set("X-Optimizations", json.Marshal(response.Optimizations))

		writeJSONResponse(w, http.StatusOK, response)
		return http.StatusOK, nil
	})
}

// HighPerformanceTagSearch handles POST /api/v1/search/tags/optimized
func (h *EnhancedSearchHandler) HighPerformanceTagSearch(w http.ResponseWriter, r *http.Request) {
	h.performanceMonitor.MonitoredHTTPOperation("high_performance_tag_search", w, func() (int, error) {
		var req models.TagSearchRequest
		if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
			writeErrorResponse(w, http.StatusBadRequest, "invalid request body", err.Error())
			return http.StatusBadRequest, err
		}

		// Validate request
		if len(req.Tags) == 0 {
			writeErrorResponse(w, http.StatusBadRequest, "at least one tag is required", "")
			return http.StatusBadRequest, nil
		}

		// Set defaults
		if req.Limit <= 0 {
			req.Limit = 20
		}
		if req.CombinationMode == "" {
			req.CombinationMode = "OR"
		}

		// Execute high-performance tag search
		response, err := h.enhancedService.HighPerformanceTagSearch(r.Context(), &req)
		if err != nil {
			writeErrorResponse(w, http.StatusInternalServerError, "tag search failed", err.Error())
			return http.StatusInternalServerError, err
		}

		// Add performance headers
		w.Header().Set("X-Response-Time", response.Duration.String())
		w.Header().Set("X-Optimizations", json.Marshal(response.Optimizations))

		writeJSONResponse(w, http.StatusOK, response)
		return http.StatusOK, nil
	})
}

// FullTextSearchOptimized handles POST /api/v1/search/fulltext/optimized
func (h *EnhancedSearchHandler) FullTextSearchOptimized(w http.ResponseWriter, r *http.Request) {
	h.performanceMonitor.MonitoredHTTPOperation("fulltext_search_optimized", w, func() (int, error) {
		var req models.FullTextRequest
		if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
			writeErrorResponse(w, http.StatusBadRequest, "invalid request body", err.Error())
			return http.StatusBadRequest, err
		}

		// Validate request
		if req.Query == "" {
			writeErrorResponse(w, http.StatusBadRequest, "query is required", "")
			return http.StatusBadRequest, nil
		}

		// Set defaults
		if req.Limit <= 0 {
			req.Limit = 15
		}
		if req.RankingMode == "" {
			req.RankingMode = "bm25"
		}

		// Execute optimized full-text search
		response, err := h.enhancedService.FullTextSearchOptimized(r.Context(), &req)
		if err != nil {
			writeErrorResponse(w, http.StatusInternalServerError, "full-text search failed", err.Error())
			return http.StatusInternalServerError, err
		}

		// Add performance headers
		if response.CacheHit {
			w.Header().Set("X-Cache", "HIT")
		} else {
			w.Header().Set("X-Cache", "MISS")
		}
		w.Header().Set("X-Response-Time", response.Duration.String())
		w.Header().Set("X-Optimizations", json.Marshal(response.Optimizations))

		writeJSONResponse(w, http.StatusOK, response)
		return http.StatusOK, nil
	})
}

// RunSearchBenchmarks handles POST /api/v1/search/benchmarks
func (h *EnhancedSearchHandler) RunSearchBenchmarks(w http.ResponseWriter, r *http.Request) {
	h.performanceMonitor.MonitoredHTTPOperation("run_search_benchmarks", w, func() (int, error) {
		// Check if user has permission to run benchmarks (in production, add auth check)

		// Execute comprehensive benchmarks
		results, err := h.enhancedService.RunSearchBenchmarks(r.Context())
		if err != nil {
			writeErrorResponse(w, http.StatusInternalServerError, "benchmark execution failed", err.Error())
			return http.StatusInternalServerError, err
		}

		// Add benchmark metadata headers
		w.Header().Set("X-Benchmark-Duration", results.Duration.String())
		w.Header().Set("X-Overall-Score", strconv.FormatFloat(results.OverallScore, 'f', 2, 64))

		writeJSONResponse(w, http.StatusOK, results)
		return http.StatusOK, nil
	})
}

// WarmSearchCache handles POST /api/v1/search/cache/warm
func (h *EnhancedSearchHandler) WarmSearchCache(w http.ResponseWriter, r *http.Request) {
	h.performanceMonitor.MonitoredHTTPOperation("warm_search_cache", w, func() (int, error) {
		var req struct {
			Patterns []string `json:"patterns"`
		}

		if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
			writeErrorResponse(w, http.StatusBadRequest, "invalid request body", err.Error())
			return http.StatusBadRequest, err
		}

		// Use default patterns if none provided
		if len(req.Patterns) == 0 {
			req.Patterns = []string{"popular_searches", "recent_queries"}
		}

		// Execute cache warming
		if err := h.enhancedService.WarmSearchCache(r.Context(), req.Patterns); err != nil {
			writeErrorResponse(w, http.StatusInternalServerError, "cache warming failed", err.Error())
			return http.StatusInternalServerError, err
		}

		response := map[string]interface{}{
			"status":   "success",
			"message":  "Cache warming completed",
			"patterns": req.Patterns,
		}

		writeJSONResponse(w, http.StatusOK, response)
		return http.StatusOK, nil
	})
}

// GetSearchStatistics handles GET /api/v1/search/statistics
func (h *EnhancedSearchHandler) GetSearchStatistics(w http.ResponseWriter, r *http.Request) {
	h.performanceMonitor.MonitoredHTTPOperation("get_search_statistics", w, func() (int, error) {
		statistics, err := h.enhancedService.GetSearchStatistics(r.Context())
		if err != nil {
			writeErrorResponse(w, http.StatusInternalServerError, "failed to get search statistics", err.Error())
			return http.StatusInternalServerError, err
		}

		writeJSONResponse(w, http.StatusOK, statistics)
		return http.StatusOK, nil
	})
}

// GetSearchHealth handles GET /api/v1/search/health
func (h *EnhancedSearchHandler) GetSearchHealth(w http.ResponseWriter, r *http.Request) {
	h.performanceMonitor.MonitoredHTTPOperation("get_search_health", w, func() (int, error) {
		// Quick health check of search subsystems
		health := map[string]interface{}{
			"status":    "healthy",
			"timestamp": time.Now(),
			"checks": map[string]string{
				"enhanced_service": "ok",
				"vector_cache":     "ok",
				"tag_cache":        "ok",
				"fulltext_cache":   "ok",
			},
		}

		// You could add actual health checks here
		// For now, we'll just return a basic health status

		writeJSONResponse(w, http.StatusOK, health)
		return http.StatusOK, nil
	})
}

// BatchSearch handles POST /api/v1/search/batch for batch search operations
func (h *EnhancedSearchHandler) BatchSearch(w http.ResponseWriter, r *http.Request) {
	h.performanceMonitor.MonitoredHTTPOperation("batch_search", w, func() (int, error) {
		var req struct {
			Queries []BatchSearchQuery `json:"queries"`
		}

		if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
			writeErrorResponse(w, http.StatusBadRequest, "invalid request body", err.Error())
			return http.StatusBadRequest, err
		}

		if len(req.Queries) == 0 {
			writeErrorResponse(w, http.StatusBadRequest, "no queries provided", "")
			return http.StatusBadRequest, nil
		}

		if len(req.Queries) > 50 { // Limit batch size
			writeErrorResponse(w, http.StatusBadRequest, "too many queries in batch (max 50)", "")
			return http.StatusBadRequest, nil
		}

		// Execute batch search
		results := make([]interface{}, len(req.Queries))
		errors := make([]string, len(req.Queries))

		for i, query := range req.Queries {
			var result interface{}
			var err error

			switch query.Type {
			case "semantic":
				result, err = h.enhancedService.OptimizedSemanticSearch(r.Context(), query.SemanticRequest)
			case "tag":
				result, err = h.enhancedService.HighPerformanceTagSearch(r.Context(), query.TagRequest)
			case "fulltext":
				result, err = h.enhancedService.FullTextSearchOptimized(r.Context(), query.FullTextRequest)
			default:
				err = fmt.Errorf("unknown query type: %s", query.Type)
			}

			if err != nil {
				errors[i] = err.Error()
			} else {
				results[i] = result
			}
		}

		response := map[string]interface{}{
			"results": results,
			"errors":  errors,
		}

		writeJSONResponse(w, http.StatusOK, response)
		return http.StatusOK, nil
	})
}

// BatchSearchQuery represents a single query in a batch search request
type BatchSearchQuery struct {
	Type             string                         `json:"type"` // "semantic", "tag", "fulltext"
	SemanticRequest  *models.OptimizedSearchRequest `json:"semantic_request,omitempty"`
	TagRequest       *models.TagSearchRequest       `json:"tag_request,omitempty"`
	FullTextRequest  *models.FullTextRequest        `json:"fulltext_request,omitempty"`
}

// SearchSuggestions handles GET /api/v1/search/suggestions
func (h *EnhancedSearchHandler) SearchSuggestions(w http.ResponseWriter, r *http.Request) {
	h.performanceMonitor.MonitoredHTTPOperation("search_suggestions", w, func() (int, error) {
		query := r.URL.Query().Get("q")
		if query == "" {
			writeErrorResponse(w, http.StatusBadRequest, "query parameter 'q' is required", "")
			return http.StatusBadRequest, nil
		}

		limit := 10
		if l := r.URL.Query().Get("limit"); l != "" {
			if parsed, err := strconv.Atoi(l); err == nil && parsed > 0 && parsed <= 50 {
				limit = parsed
			}
		}

		// Generate search suggestions based on query
		suggestions := h.generateSearchSuggestions(query, limit)

		response := map[string]interface{}{
			"query":       query,
			"suggestions": suggestions,
			"count":       len(suggestions),
		}

		writeJSONResponse(w, http.StatusOK, response)
		return http.StatusOK, nil
	})
}

// GetPopularSearches handles GET /api/v1/search/popular
func (h *EnhancedSearchHandler) GetPopularSearches(w http.ResponseWriter, r *http.Request) {
	h.performanceMonitor.MonitoredHTTPOperation("get_popular_searches", w, func() (int, error) {
		statistics, err := h.enhancedService.GetSearchStatistics(r.Context())
		if err != nil {
			writeErrorResponse(w, http.StatusInternalServerError, "failed to get search statistics", err.Error())
			return http.StatusInternalServerError, err
		}

		// Extract popular searches
		popularSearches := statistics.PopularSearches
		if len(popularSearches) > 20 {
			popularSearches = popularSearches[:20] // Limit to top 20
		}

		response := map[string]interface{}{
			"popular_searches": popularSearches,
			"total_searches":   statistics.TotalSearches,
		}

		writeJSONResponse(w, http.StatusOK, response)
		return http.StatusOK, nil
	})
}

// SearchAnalytics handles GET /api/v1/search/analytics
func (h *EnhancedSearchHandler) SearchAnalytics(w http.ResponseWriter, r *http.Request) {
	h.performanceMonitor.MonitoredHTTPOperation("search_analytics", w, func() (int, error) {
		// Parse query parameters for analytics filtering
		timeRange := r.URL.Query().Get("time_range") // "1h", "24h", "7d", "30d"
		if timeRange == "" {
			timeRange = "24h"
		}

		// Get comprehensive search statistics
		statistics, err := h.enhancedService.GetSearchStatistics(r.Context())
		if err != nil {
			writeErrorResponse(w, http.StatusInternalServerError, "failed to get search analytics", err.Error())
			return http.StatusInternalServerError, err
		}

		// Build analytics response
		analytics := map[string]interface{}{
			"time_range":           timeRange,
			"total_searches":       statistics.TotalSearches,
			"average_response_time": statistics.AverageResponseTime.Milliseconds(),
			"cache_hit_rate":       statistics.CacheHitRate,
			"popular_searches":     statistics.PopularSearches[:min(10, len(statistics.PopularSearches))],
			"slow_queries":         statistics.SlowQueries[:min(5, len(statistics.SlowQueries))],
			"performance_metrics":  statistics.PerformanceMetrics,
		}

		writeJSONResponse(w, http.StatusOK, analytics)
		return http.StatusOK, nil
	})
}

// Helper methods

func (h *EnhancedSearchHandler) generateSearchSuggestions(query string, limit int) []string {
	// This is a simplified implementation
	// In production, you would implement sophisticated suggestion algorithms
	suggestions := []string{
		query + " tutorial",
		query + " example",
		query + " guide",
		query + " documentation",
		query + " best practices",
	}

	if len(suggestions) > limit {
		suggestions = suggestions[:limit]
	}

	return suggestions
}

func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}