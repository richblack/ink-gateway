# å¤šæ¨¡æ…‹ MCP ç³»çµ±è¨­è¨ˆæ–‡ä»¶

## æ¦‚è¿°

æœ¬è¨­è¨ˆæ–‡ä»¶æè¿°å¦‚ä½•å°‡ç¾æœ‰çš„ Ink-Gateway ç³»çµ±æ“´å±•ç‚ºæ”¯æ´å¤šæ¨¡æ…‹ï¼ˆæ–‡å­—+åœ–ç‰‡ï¼‰çš„çŸ¥è­˜ç®¡ç†ç³»çµ±ï¼Œä¸¦é€é MCP (Model Context Protocol) æä¾›çµ±ä¸€çš„å­˜å–ä»‹é¢ã€‚è¨­è¨ˆé‡é»åœ¨æ–¼æœ€å°åŒ–å°ç¾æœ‰æ¶æ§‹çš„å½±éŸ¿ï¼ŒåŒæ™‚æä¾›å¼·å¤§çš„åœ–ç‰‡è™•ç†å’Œèªç¾©æœå°‹èƒ½åŠ›ã€‚

## æ¶æ§‹è¨­è¨ˆ

### æ•´é«”æ¶æ§‹åœ–

```mermaid
graph TB
    subgraph "AI Agents å‰ç«¯å±¤"
        A[Obsidian Plugin] 
        B[Claude Desktop]
        C[Claude Code]
        D[Gemini CLI]
        E[Codex]
        F[å…¶ä»– AI Agents]
    end
    
    subgraph "MCP ç”Ÿæ…‹ç³»çµ±"
        G[Ink-Gateway MCP Server]
        H[Slide Generator MCP]
        I[å…¶ä»– MCP Tools]
    end
    
    subgraph "Ink-Gateway æ ¸å¿ƒ"
        J[HTTP API Server]
        K[åœ–ç‰‡è™•ç†æœå‹™]
        L[å¤šæ¨¡æ…‹æœå°‹æœå‹™]
        M[å„²å­˜æŠ½è±¡å±¤]
    end
    
    subgraph "å¤–éƒ¨ AI æœå‹™"
        N[GPT-4 Vision API]
        O[CLIP Embedding API]
        P[OpenAI Embedding API]
    end
    
    subgraph "å„²å­˜å±¤"
        Q[Supabase API<br/>è³‡æ–™åº«+å‘é‡]
        R[Supabase Storage<br/>åœ–ç‰‡æª”æ¡ˆ]
        S[æœ¬åœ°æª”æ¡ˆç³»çµ±]
        T[Google Drive]
        U[æœªä¾†é›²ç«¯æœå‹™]
    end
    
    A --> G
    B --> G
    C --> G
    D --> G
    E --> G
    F --> G
    
    H --> G
    I --> G
    
    G --> J
    
    J --> K
    J --> L
    J --> M
    
    K --> N
    K --> O
    L --> P
    
    M --> R
    M --> S
    M --> T
    M --> U
    
    J --> Q
```

### æ ¸å¿ƒè¨­è¨ˆåŸå‰‡

1. **æœ€å°ä¾µå…¥æ€§**: æ“´å±•ç¾æœ‰ UnifiedChunk æ¨¡å‹ï¼Œä¸ç ´å£ç¾æœ‰åŠŸèƒ½
2. **å¯æ’æ‹”æ¶æ§‹**: å„²å­˜ã€AI æœå‹™éƒ½æ¡ç”¨ä»‹é¢è¨­è¨ˆï¼Œæ˜“æ–¼æ“´å±•
3. **æ•ˆèƒ½å„ªå…ˆ**: æ‰¹æ¬¡è™•ç†ã€å¿«å–æ©Ÿåˆ¶ã€ä¸¦è¡Œè™•ç†
4. **Supabase å„ªå…ˆ**: åœ–ç‰‡å„²å­˜ä½¿ç”¨ self-hosted Supabase Storage
5. **MCP æ¨™æº–**: å®Œå…¨ç¬¦åˆ MCP å”è­°è¦ç¯„

### åŠŸèƒ½åˆ†é¡

#### ğŸ”§ æ“´å±•ç¾æœ‰åŠŸèƒ½ï¼š
- **å‘é‡æœå°‹**: æ“´å±•ç¾æœ‰ embeddings è¡¨æ”¯æ´åœ–ç‰‡å‘é‡
- **æœå°‹æœå‹™**: æ“´å±•ç¾æœ‰ SearchService æ”¯æ´å¤šæ¨¡æ…‹æœå°‹
- **è³‡æ–™æ¨¡å‹**: æ“´å±• UnifiedChunk.metadata æ”¯æ´åœ–ç‰‡è³‡è¨Š

#### âœ¨ å…¨æ–°åŠŸèƒ½ï¼š
- **Supabase Storage æ•´åˆ**: å…¨æ–°çš„æª”æ¡ˆå„²å­˜åŠŸèƒ½
- **Vision AI æœå‹™**: GPT-4 Vision å’Œ CLIP æ•´åˆ
- **MCP Server**: å®Œæ•´çš„ MCP å”è­°å¯¦ä½œ
- **åœ–ç‰‡æ‰¹æ¬¡è™•ç†**: è³‡æ–™å¤¾æƒæå’Œæ‰¹æ¬¡ä¸Šå‚³åŠŸèƒ½
- **å¤šæ¨¡æ…‹æœå°‹**: æ–‡å­—+åœ–ç‰‡æ··åˆæœå°‹æ¼”ç®—æ³•

## çµ„ä»¶å’Œä»‹é¢

### 1. è³‡æ–™æ¨¡å‹æ“´å±•

#### 1.1 UnifiedChunk å…ƒè³‡æ–™æ“´å±•

ç¾æœ‰çš„ `UnifiedChunk.metadata` æ¬„ä½å°‡ç”¨æ–¼å„²å­˜åœ–ç‰‡ç›¸é—œè³‡è¨Šï¼š

```json
{
  "media_type": "image",
  "storage": {
    "type": "local|google_drive|google_photos|nas",
    "storage_id": "unique-storage-identifier",
    "url": "accessible-url",
    "original_filename": "user-friendly-name.png",
    "file_hash": "sha256-hash-for-deduplication",
    "uploaded_at": "2025-01-15T10:30:00Z"
  },
  "image_properties": {
    "format": "png|jpg|jpeg|gif|webp",
    "size_bytes": 102400,
    "width": 1920,
    "height": 1080,
    "mime_type": "image/png"
  },
  "ai_analysis": {
    "description": "AI ç”Ÿæˆçš„è©³ç´°åœ–ç‰‡æè¿°",
    "model": "gpt-4-vision-preview",
    "tags": ["architecture", "microservices", "diagram"],
    "analyzed_at": "2025-01-15T10:30:05Z",
    "confidence": 0.95
  },
  "embeddings": {
    "image": {
      "model": "clip-vit-b-32",
      "dimensions": 512,
      "embedding_id": "embedding-uuid-1"
    },
    "text": {
      "model": "text-embedding-3-small", 
      "dimensions": 512,
      "embedding_id": "embedding-uuid-2"
    }
  }
}
```

#### 1.2 Embeddings è¡¨æ“´å±•

éœ€è¦æ“´å±•ç¾æœ‰çš„ embeddings è¡¨ä»¥æ”¯æ´å¤šç¨®å‘é‡é¡å‹ï¼š

```sql
-- æ“´å±• embeddings è¡¨
ALTER TABLE embeddings 
ADD COLUMN vector_type VARCHAR(50) NOT NULL DEFAULT 'text',
ADD COLUMN model_name VARCHAR(100) NOT NULL DEFAULT 'text-embedding-3-small',
ADD COLUMN metadata JSONB;

-- å»ºç«‹ç´¢å¼•
CREATE INDEX idx_embeddings_vector_type ON embeddings(vector_type);
CREATE INDEX idx_embeddings_model ON embeddings(model_name);
CREATE INDEX idx_text_vectors ON embeddings USING ivfflat (vector vector_cosine_ops) 
WHERE vector_type = 'text';
CREATE INDEX idx_image_vectors ON embeddings USING ivfflat (vector vector_cosine_ops) 
WHERE vector_type = 'image';
```

### 2. å„²å­˜æŠ½è±¡å±¤è¨­è¨ˆ

#### 2.0 å„²å­˜ç­–ç•¥é¸æ“‡

æˆ‘å€‘æä¾›å¤šç¨®å„²å­˜é¸é …ï¼Œå„æœ‰å„ªç¼ºé»ï¼š

| å„²å­˜æ–¹å¼ | å„ªé» | ç¼ºé» | é©ç”¨æƒ…å¢ƒ |
|---------|------|------|----------|
| **Supabase Storage** | èˆ‡è³‡æ–™åº«æ•´åˆã€CDNæ”¯æ´ã€æ¬Šé™æ§åˆ¶ | 1GBå…è²»é¡åº¦ã€è¢«ç¶å®š | å°å‹å°ˆæ¡ˆã€å¿«é€Ÿé–‹ç™¼ |
| **Google Drive** | 15GBå…è²»ç©ºé–“ã€ç†Ÿæ‚‰ä»‹é¢ã€è·¨è£ç½®åŒæ­¥ | APIé…é¡é™åˆ¶ã€é€Ÿåº¦è¼ƒæ…¢ | å€‹äººä½¿ç”¨ã€å¤§é‡åœ–ç‰‡ |
| **æœ¬åœ°æª”æ¡ˆç³»çµ±** | é€Ÿåº¦å¿«ã€ç„¡é™åˆ¶ã€å®Œå…¨æ§åˆ¶ | ç„¡è·¨è£ç½®åŒæ­¥ã€ç„¡å‚™ä»½ | é–‹ç™¼æ¸¬è©¦ã€é›¢ç·šä½¿ç”¨ |
| **NAS/è‡ªå»º** | å®Œå…¨æ§åˆ¶ã€å¤§å®¹é‡ã€é«˜é€Ÿ | éœ€è¦ç¶­è­·ã€è¤‡é›œè¨­å®š | ä¼æ¥­ä½¿ç”¨ã€å¤§é‡è³‡æ–™ |

**å»ºè­°çš„å¯¦ä½œé †åº**ï¼š
1. **ç¬¬ä¸€æœŸ**: Supabase Storage (ä¸»è¦å„²å­˜) + æœ¬åœ°å„²å­˜ (é–‹ç™¼æ¸¬è©¦/é›¢ç·šå‚™ä»½)
2. **ç¬¬äºŒæœŸ**: Google Drive (å¯é¸ï¼Œä½œç‚ºé¡å¤–å‚™ä»½æˆ–é·ç§»é¸é …)
3. **ç¬¬ä¸‰æœŸ**: NAS æ”¯æ´ (ä¼æ¥­éœ€æ±‚æˆ–ç‰¹æ®Šæƒ…å¢ƒ)

**é…ç½®ç¯„ä¾‹**ï¼š
```yaml
storage:
  primary: "supabase"     # ä¸»è¦å„²å­˜ï¼ˆä½ çš„ self-hostedï¼‰
  fallback: "local"       # å‚™ç”¨å„²å­˜ï¼ˆé–‹ç™¼æ¸¬è©¦ï¼‰
  supabase:
    url: "https://your-supabase-server.com"
    bucket: "ink-images"
    # çµ±ä¸€çš„åœ–ç‰‡å„²å­˜ä½ç½®ï¼Œå–ä»£ Google Drive çš„è§’è‰²
    # æ‰€æœ‰å°ˆæ¡ˆåœ–ç‰‡éƒ½å­˜åœ¨é€™è£¡ï¼š
    # /ink-images/obsidian/notes/
    # /ink-images/vscode/projects/
    # /ink-images/general/screenshots/
  local:
    base_path: "/tmp/ink-images"  # é–‹ç™¼æ¸¬è©¦ç”¨
    base_url: "file:///tmp/ink-images"
```

#### 2.1 StorageAdapter ä»‹é¢

```go
// MediaStorageAdapter å®šç¾©çµ±ä¸€çš„å„²å­˜ä»‹é¢
type MediaStorageAdapter interface {
    // ä¸Šå‚³æª”æ¡ˆä¸¦è¿”å›å„²å­˜è³‡è¨Š
    Upload(ctx context.Context, file io.Reader, metadata *MediaMetadata) (*StorageResult, error)
    
    // æ ¹æ“š storage_id å–å¾—å­˜å– URL
    GetURL(ctx context.Context, storageID string) (string, error)
    
    // ä¸‹è¼‰æª”æ¡ˆå…§å®¹
    Download(ctx context.Context, storageID string) (io.ReadCloser, error)
    
    // åˆªé™¤æª”æ¡ˆ
    Delete(ctx context.Context, storageID string) error
    
    // æƒæè³‡æ–™å¤¾ä¸­çš„åœ–ç‰‡æª”æ¡ˆ
    ScanFolder(ctx context.Context, folderPath string) ([]MediaFile, error)
    
    // å–å¾—å„²å­˜é¡å‹
    GetStorageType() StorageType
    
    // å¥åº·æª¢æŸ¥
    HealthCheck(ctx context.Context) error
}

// MediaMetadata åœ–ç‰‡å…ƒè³‡æ–™
type MediaMetadata struct {
    OriginalFilename string
    ContentType      string
    Size            int64
    Width           int
    Height          int
    Hash            string // SHA256
}

// StorageResult ä¸Šå‚³çµæœ
type StorageResult struct {
    StorageID   string
    URL         string
    StorageType StorageType
    UploadedAt  time.Time
}

// StorageType å„²å­˜é¡å‹
type StorageType string

const (
    StorageTypeLocal        StorageType = "local"
    StorageTypeSupabase     StorageType = "supabase"
    StorageTypeGoogleDrive  StorageType = "google_drive"
    StorageTypeGooglePhotos StorageType = "google_photos"
    StorageTypeNAS          StorageType = "nas"
)
```

#### 2.2 å„²å­˜å¯¦ä½œé¸é …

æˆ‘å€‘æä¾›å¤šç¨®å„²å­˜å¯¦ä½œï¼ŒåŒ…æ‹¬ Supabase Storageï¼š

```go
// SupabaseStorageAdapter Supabase Storage å¯¦ä½œ
type SupabaseStorageAdapter struct {
    client    *supabase.Client
    bucket    string
    baseURL   string
}

func (s *SupabaseStorageAdapter) Upload(ctx context.Context, file io.Reader, metadata *MediaMetadata) (*StorageResult, error) {
    // 1. ç”Ÿæˆæª”æ¡ˆè·¯å¾‘ (ä½¿ç”¨ hash é¿å…é‡è¤‡)
    filePath := fmt.Sprintf("images/%s/%s_%s", 
        time.Now().Format("2006/01"), 
        metadata.Hash[:16],
        metadata.OriginalFilename)
    
    // 2. ä¸Šå‚³åˆ° Supabase Storage
    resp, err := s.client.Storage.
        From(s.bucket).
        Upload(filePath, file, supabase.FileOptions{
            ContentType: &metadata.ContentType,
            Upsert:      false, // ä¸è¦†è“‹ç¾æœ‰æª”æ¡ˆ
        })
    
    if err != nil {
        return nil, fmt.Errorf("supabase upload failed: %w", err)
    }
    
    // 3. å–å¾—å…¬é–‹ URL
    publicURL := s.client.Storage.From(s.bucket).GetPublicURL(filePath)
    
    return &StorageResult{
        StorageID:   filePath,
        URL:         publicURL.SignedURL,
        StorageType: StorageTypeSupabase,
        UploadedAt:  time.Now(),
    }, nil
}

// LocalStorageAdapter æœ¬åœ°æª”æ¡ˆç³»çµ±å¯¦ä½œ
type LocalStorageAdapter struct {
    basePath string
    baseURL  string
}

// GoogleDriveAdapter Google Drive å¯¦ä½œ (æœªä¾†)
type GoogleDriveAdapter struct {
    service  *drive.Service
    folderID string
}

func (l *LocalStorageAdapter) Upload(ctx context.Context, file io.Reader, metadata *MediaMetadata) (*StorageResult, error) {
    // 1. ç”Ÿæˆå”¯ä¸€æª”å (ä½¿ç”¨ hash + æ™‚é–“æˆ³)
    storageID := fmt.Sprintf("%s_%d%s", 
        metadata.Hash[:16], 
        time.Now().Unix(), 
        filepath.Ext(metadata.OriginalFilename))
    
    // 2. å»ºç«‹ç›®éŒ„çµæ§‹ (æŒ‰æ—¥æœŸåˆ†çµ„)
    dateDir := time.Now().Format("2006/01/02")
    fullDir := filepath.Join(l.basePath, dateDir)
    os.MkdirAll(fullDir, 0755)
    
    // 3. å„²å­˜æª”æ¡ˆ
    destPath := filepath.Join(fullDir, storageID)
    destFile, err := os.Create(destPath)
    if err != nil {
        return nil, fmt.Errorf("failed to create file: %w", err)
    }
    defer destFile.Close()
    
    _, err = io.Copy(destFile, file)
    if err != nil {
        return nil, fmt.Errorf("failed to write file: %w", err)
    }
    
    // 4. è¿”å›çµæœ
    return &StorageResult{
        StorageID:   filepath.Join(dateDir, storageID),
        URL:         fmt.Sprintf("%s/%s/%s", l.baseURL, dateDir, storageID),
        StorageType: StorageTypeLocal,
        UploadedAt:  time.Now(),
    }, nil
}
```

### 3. åœ–ç‰‡è™•ç†æœå‹™

#### 3.1 MediaProcessor ä»‹é¢

```go
// MediaProcessor åœ–ç‰‡è™•ç†æœå‹™ä»‹é¢
type MediaProcessor interface {
    // è™•ç†å–®å¼µåœ–ç‰‡ï¼ˆä¸Šå‚³ã€åˆ†æã€ç´¢å¼•ï¼‰
    ProcessImage(ctx context.Context, req *ProcessImageRequest) (*ProcessImageResult, error)
    
    // æ‰¹æ¬¡è™•ç†åœ–ç‰‡
    BatchProcessImages(ctx context.Context, req *BatchProcessRequest) (*BatchProcessResult, error)
    
    // åˆ†æåœ–ç‰‡å…§å®¹
    AnalyzeImage(ctx context.Context, imageURL string) (*ImageAnalysis, error)
    
    // ç”Ÿæˆåœ–ç‰‡å‘é‡
    GenerateImageEmbedding(ctx context.Context, imageURL string) ([]float64, error)
    
    // è¨ˆç®—æª”æ¡ˆé›œæ¹Š
    CalculateHash(ctx context.Context, file io.Reader) (string, error)
}

// ProcessImageRequest åœ–ç‰‡è™•ç†è«‹æ±‚
type ProcessImageRequest struct {
    File             io.Reader
    OriginalFilename string
    PageID          *string
    Tags            []string
    AutoAnalyze     bool
    AutoEmbed       bool
    StorageType     StorageType
}

// ProcessImageResult åœ–ç‰‡è™•ç†çµæœ
type ProcessImageResult struct {
    ChunkID      string
    StorageID    string
    URL          string
    Hash         string
    Analysis     *ImageAnalysis
    EmbeddingIDs map[string]string // "image" -> embedding_id, "text" -> embedding_id
}

// ImageAnalysis AI åœ–ç‰‡åˆ†æçµæœ
type ImageAnalysis struct {
    Description string
    Tags        []string
    Model       string
    Confidence  float64
    AnalyzedAt  time.Time
}
```

#### 3.2 Vision AI æ•´åˆ

```go
// VisionAIService Vision AI æœå‹™ä»‹é¢
type VisionAIService interface {
    AnalyzeImage(ctx context.Context, imageURL string, options *AnalysisOptions) (*ImageAnalysis, error)
}

// AnalysisOptions åˆ†æé¸é …
type AnalysisOptions struct {
    DetailLevel string // "low", "medium", "high"
    Language    string // "zh-TW", "en"
    MaxTokens   int
}

// GPT4VisionService GPT-4 Vision å¯¦ä½œ
type GPT4VisionService struct {
    apiKey     string
    httpClient *http.Client
}

func (g *GPT4VisionService) AnalyzeImage(ctx context.Context, imageURL string, options *AnalysisOptions) (*ImageAnalysis, error) {
    prompt := `è«‹è©³ç´°æè¿°é€™å¼µåœ–ç‰‡çš„å…§å®¹ï¼ŒåŒ…æ‹¬ï¼š
1. ä¸»è¦ç‰©ä»¶å’Œå…ƒç´ 
2. åœ–ç‰‡é¡å‹ï¼ˆæˆªåœ–ã€åœ–è¡¨ã€ç…§ç‰‡ç­‰ï¼‰
3. æŠ€è¡“ç›¸é—œå…§å®¹ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
4. å¯èƒ½çš„ç”¨é€”æˆ–æƒ…å¢ƒ
5. å»ºè­°çš„æ¨™ç±¤ï¼ˆç”¨é€—è™Ÿåˆ†éš”ï¼‰

è«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚`

    // æ§‹å»º GPT-4 Vision API è«‹æ±‚
    request := map[string]interface{}{
        "model": "gpt-4-vision-preview",
        "messages": []map[string]interface{}{
            {
                "role": "user",
                "content": []map[string]interface{}{
                    {
                        "type": "text",
                        "text": prompt,
                    },
                    {
                        "type": "image_url",
                        "image_url": map[string]string{
                            "url": imageURL,
                        },
                    },
                },
            },
        },
        "max_tokens": options.MaxTokens,
    }
    
    // åŸ·è¡Œ API å‘¼å«ä¸¦è§£æçµæœ
    // ... å¯¦ä½œç´°ç¯€
}
```

### 4. å¤šæ¨¡æ…‹æœå°‹æœå‹™

#### 4.1 MultimodalSearchService ä»‹é¢

```go
// MultimodalSearchService å¤šæ¨¡æ…‹æœå°‹æœå‹™
type MultimodalSearchService interface {
    // æ–‡å­—æœå°‹ï¼ˆåŒ…å«åœ–ç‰‡ AI æè¿°ï¼‰
    SearchText(ctx context.Context, req *TextSearchRequest) (*SearchResponse, error)
    
    // åœ–ç‰‡æœå°‹ï¼ˆå‘é‡ç›¸ä¼¼åº¦ï¼‰
    SearchImages(ctx context.Context, req *ImageSearchRequest) (*SearchResponse, error)
    
    // æ··åˆæœå°‹ï¼ˆæ–‡å­—+åœ–ç‰‡ï¼‰
    HybridSearch(ctx context.Context, req *HybridSearchRequest) (*SearchResponse, error)
    
    // ä»¥åœ–æœåœ–
    SearchByImage(ctx context.Context, req *ImageSimilarityRequest) (*SearchResponse, error)
    
    // ç‚º Slide Generator æ¨è–¦åœ–ç‰‡
    RecommendImagesForSlides(ctx context.Context, req *SlideImageRequest) (*ImageRecommendationResponse, error)
}

// HybridSearchRequest æ··åˆæœå°‹è«‹æ±‚
type HybridSearchRequest struct {
    TextQuery    string
    ImageQuery   string // åœ–ç‰‡ URL æˆ– base64
    Weights      SearchWeights
    Filters      SearchFilters
    Limit        int
    MinSimilarity float64
}

// SearchWeights æœå°‹æ¬Šé‡
type SearchWeights struct {
    Text  float64 // 0.0 - 1.0
    Image float64 // 0.0 - 1.0
}

// SearchFilters æœå°‹éæ¿¾å™¨
type SearchFilters struct {
    MediaType    *string   // "image", "text", "all"
    StorageType  *string   // "local", "google_drive"
    Tags         []string
    DateRange    *DateRange
    ImageFormat  *string   // "png", "jpg"
    MinImageSize *int64
}

// SearchResponse æœå°‹å›æ‡‰
type SearchResponse struct {
    Results     []SearchResult
    TotalCount  int
    SearchTime  time.Duration
    Query       string
    MatchTypes  []string // ["text_vector", "image_vector", "hybrid"]
}

// SearchResult æœå°‹çµæœé …ç›®
type SearchResult struct {
    Chunk       *models.UnifiedChunkRecord
    Similarity  float64
    MatchType   string // "text_vector", "image_vector", "hybrid"
    Explanation string // åŒ¹é…åŸå› èªªæ˜
}
```

### 5. MCP Server è¨­è¨ˆ

#### 5.1 MCP Tools å®šç¾©

```go
// MCP Tools å¯¦ä½œ
var MCPTools = map[string]MCPTool{
    "ink_search_chunks": &SearchChunksTool{},
    "ink_create_chunk": &CreateChunkTool{},
    "ink_analyze_image": &AnalyzeImageTool{},
    "ink_batch_process_images": &BatchProcessImagesTool{},
    "ink_get_images_for_slides": &GetImagesForSlidesTool{},
    "ink_upload_image": &UploadImageTool{},
    "ink_search_images": &SearchImagesTool{},
    "ink_hybrid_search": &HybridSearchTool{},
}

// SearchChunksTool æœå°‹çŸ¥è­˜å¡Šå·¥å…·
type SearchChunksTool struct{}

func (t *SearchChunksTool) Execute(ctx context.Context, args map[string]interface{}) (*MCPResult, error) {
    // è§£æåƒæ•¸
    query := args["query"].(string)
    searchType := getStringArg(args, "type", "all") // "text", "image", "all"
    limit := getIntArg(args, "limit", 10)
    minSimilarity := getFloatArg(args, "min_similarity", 0.7)
    includeImages := getBoolArg(args, "include_images", true)
    
    // æ ¹æ“šæœå°‹é¡å‹åŸ·è¡Œä¸åŒçš„æœå°‹
    switch searchType {
    case "text":
        return t.searchText(ctx, query, limit, minSimilarity)
    case "image":
        return t.searchImages(ctx, query, limit, minSimilarity)
    case "all", "hybrid":
        return t.hybridSearch(ctx, query, limit, minSimilarity, includeImages)
    default:
        return nil, fmt.Errorf("unsupported search type: %s", searchType)
    }
}

// AnalyzeImageTool åœ–ç‰‡åˆ†æå·¥å…·
type AnalyzeImageTool struct{}

func (t *AnalyzeImageTool) Execute(ctx context.Context, args map[string]interface{}) (*MCPResult, error) {
    imageURL := args["image_url"].(string)
    generateEmbedding := getBoolArg(args, "generate_embedding", true)
    detailLevel := getStringArg(args, "detail_level", "medium")
    
    // åˆ†æåœ–ç‰‡
    analysis, err := mediaProcessor.AnalyzeImage(ctx, imageURL)
    if err != nil {
        return nil, fmt.Errorf("failed to analyze image: %w", err)
    }
    
    result := map[string]interface{}{
        "description": analysis.Description,
        "tags":        analysis.Tags,
        "model":       analysis.Model,
        "confidence":  analysis.Confidence,
    }
    
    // ç”Ÿæˆå‘é‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if generateEmbedding {
        embedding, err := mediaProcessor.GenerateImageEmbedding(ctx, imageURL)
        if err != nil {
            return nil, fmt.Errorf("failed to generate embedding: %w", err)
        }
        
        // å„²å­˜å‘é‡åˆ°è³‡æ–™åº«
        embeddingID, err := storeEmbedding(ctx, embedding, "image", "clip-vit-b-32")
        if err != nil {
            return nil, fmt.Errorf("failed to store embedding: %w", err)
        }
        
        result["embedding_id"] = embeddingID
    }
    
    return &MCPResult{
        Content: []MCPContent{{
            Type: "text",
            Text: fmt.Sprintf("åœ–ç‰‡åˆ†æå®Œæˆï¼š%s", analysis.Description),
        }},
        IsError: false,
    }, nil
}

// GetImagesForSlidesTool Slide Generator åœ–ç‰‡æ¨è–¦å·¥å…·
type GetImagesForSlidesTool struct{}

func (t *GetImagesForSlidesTool) Execute(ctx context.Context, args map[string]interface{}) (*MCPResult, error) {
    textContent := args["text_content"].(string)
    maxSuggestions := getIntArg(args, "max_suggestions", 5)
    context := getStringArg(args, "context", "")
    
    // å»ºç«‹æ¨è–¦è«‹æ±‚
    req := &SlideImageRequest{
        TextContent:    textContent,
        Context:        context,
        MaxSuggestions: maxSuggestions,
        MinRelevance:   0.7,
    }
    
    // åŸ·è¡Œæ¨è–¦
    recommendations, err := multimodalSearch.RecommendImagesForSlides(ctx, req)
    if err != nil {
        return nil, fmt.Errorf("failed to get image recommendations: %w", err)
    }
    
    // æ ¼å¼åŒ–çµæœ
    suggestions := make([]map[string]interface{}, len(recommendations.Suggestions))
    for i, suggestion := range recommendations.Suggestions {
        suggestions[i] = map[string]interface{}{
            "chunk_id":        suggestion.ChunkID,
            "image_url":       suggestion.ImageURL,
            "description":     suggestion.Description,
            "relevance_score": suggestion.RelevanceScore,
            "reason":          suggestion.Reason,
        }
    }
    
    return &MCPResult{
        Content: []MCPContent{{
            Type: "text",
            Text: fmt.Sprintf("æ‰¾åˆ° %d å€‹ç›¸é—œåœ–ç‰‡å»ºè­°", len(suggestions)),
        }},
        IsError: false,
    }, nil
}
```

## è³‡æ–™æ¨¡å‹

### 1. ç¾æœ‰æ¨¡å‹ä¿æŒä¸è®Š

ç¾æœ‰çš„ `UnifiedChunkRecord` çµæ§‹ä¿æŒå®Œå…¨ä¸è®Šï¼Œæ‰€æœ‰åœ–ç‰‡ç›¸é—œè³‡è¨Šéƒ½å„²å­˜åœ¨ `metadata` æ¬„ä½ä¸­ã€‚

### 2. æ–°å¢è¼”åŠ©æ¨¡å‹

```go
// MediaFile æƒæåˆ°çš„åª’é«”æª”æ¡ˆ
type MediaFile struct {
    Path         string
    Filename     string
    Size         int64
    ModifiedAt   time.Time
    ContentType  string
    Hash         string
}

// BatchProcessStatus æ‰¹æ¬¡è™•ç†ç‹€æ…‹
type BatchProcessStatus struct {
    BatchID      string
    TotalFiles   int
    ProcessedFiles int
    FailedFiles  int
    Status       string // "processing", "completed", "failed", "paused"
    StartedAt    time.Time
    CompletedAt  *time.Time
    Errors       []BatchError
}

// BatchError æ‰¹æ¬¡è™•ç†éŒ¯èª¤
type BatchError struct {
    Filename string
    Error    string
    Timestamp time.Time
}

// ImageRecommendation åœ–ç‰‡æ¨è–¦
type ImageRecommendation struct {
    ChunkID        string
    ImageURL       string
    Description    string
    RelevanceScore float64
    Reason         string
    Tags           []string
}
```

## éŒ¯èª¤è™•ç†

### 1. éŒ¯èª¤é¡å‹å®šç¾©

```go
// å¤šæ¨¡æ…‹ç³»çµ±ç‰¹å®šéŒ¯èª¤
var (
    ErrUnsupportedImageFormat = errors.New("unsupported image format")
    ErrImageTooLarge         = errors.New("image file too large")
    ErrStorageNotAvailable   = errors.New("storage service not available")
    ErrVisionAPIFailed       = errors.New("vision API analysis failed")
    ErrEmbeddingFailed       = errors.New("embedding generation failed")
    ErrDuplicateImage        = errors.New("duplicate image detected")
)

// MediaProcessingError åª’é«”è™•ç†éŒ¯èª¤
type MediaProcessingError struct {
    Operation string
    Filename  string
    Cause     error
}

func (e *MediaProcessingError) Error() string {
    return fmt.Sprintf("media processing failed [%s] for file %s: %v", 
        e.Operation, e.Filename, e.Cause)
}
```

### 2. éŒ¯èª¤è™•ç†ç­–ç•¥

1. **é‡è©¦æ©Ÿåˆ¶**: AI API å‘¼å«å¤±æ•—æ™‚è‡ªå‹•é‡è©¦
2. **é™ç´šè™•ç†**: Vision API å¤±æ•—æ™‚ä½¿ç”¨æª”åä½œç‚ºæè¿°
3. **éƒ¨åˆ†æˆåŠŸ**: æ‰¹æ¬¡è™•ç†ä¸­å–®å€‹æª”æ¡ˆå¤±æ•—ä¸å½±éŸ¿å…¶ä»–æª”æ¡ˆ
4. **éŒ¯èª¤è¨˜éŒ„**: è©³ç´°è¨˜éŒ„æ‰€æœ‰éŒ¯èª¤ä¾›å¾ŒçºŒåˆ†æ

## æ¸¬è©¦ç­–ç•¥

### 1. å–®å…ƒæ¸¬è©¦

```go
// å„²å­˜é©é…å™¨æ¸¬è©¦
func TestLocalStorageAdapter_Upload(t *testing.T) {
    adapter := NewLocalStorageAdapter("/tmp/test", "file:///tmp/test")
    
    // æ¸¬è©¦æ­£å¸¸ä¸Šå‚³
    file := strings.NewReader("test image content")
    metadata := &MediaMetadata{
        OriginalFilename: "test.png",
        ContentType:      "image/png",
        Size:            17,
        Hash:            "test-hash",
    }
    
    result, err := adapter.Upload(context.Background(), file, metadata)
    assert.NoError(t, err)
    assert.NotEmpty(t, result.StorageID)
    assert.Contains(t, result.URL, "test-hash")
}

// åœ–ç‰‡è™•ç†æœå‹™æ¸¬è©¦
func TestMediaProcessor_ProcessImage(t *testing.T) {
    processor := NewMediaProcessor(mockStorage, mockVisionAI, mockEmbedding)
    
    req := &ProcessImageRequest{
        File:             mockImageFile(),
        OriginalFilename: "architecture.png",
        AutoAnalyze:     true,
        AutoEmbed:       true,
    }
    
    result, err := processor.ProcessImage(context.Background(), req)
    assert.NoError(t, err)
    assert.NotEmpty(t, result.ChunkID)
    assert.NotEmpty(t, result.Analysis.Description)
}
```

### 2. æ•´åˆæ¸¬è©¦

```go
// MCP å·¥å…·æ•´åˆæ¸¬è©¦
func TestMCPTools_Integration(t *testing.T) {
    // è¨­å®šæ¸¬è©¦ç’°å¢ƒ
    server := setupTestMCPServer()
    
    // æ¸¬è©¦åœ–ç‰‡ä¸Šå‚³
    uploadArgs := map[string]interface{}{
        "image_path": "testdata/sample.png",
        "auto_analyze": true,
    }
    
    result, err := server.ExecuteTool("ink_upload_image", uploadArgs)
    assert.NoError(t, err)
    
    chunkID := extractChunkID(result)
    
    // æ¸¬è©¦æœå°‹
    searchArgs := map[string]interface{}{
        "query": "architecture diagram",
        "type": "image",
    }
    
    searchResult, err := server.ExecuteTool("ink_search_chunks", searchArgs)
    assert.NoError(t, err)
    assert.Contains(t, searchResult.Content[0].Text, chunkID)
}
```

### 3. æ•ˆèƒ½æ¸¬è©¦

```go
// æ‰¹æ¬¡è™•ç†æ•ˆèƒ½æ¸¬è©¦
func BenchmarkBatchProcessing(b *testing.B) {
    processor := NewMediaProcessor(storage, visionAI, embedding)
    
    // æº–å‚™æ¸¬è©¦æª”æ¡ˆ
    files := generateTestImages(100)
    
    b.ResetTimer()
    for i := 0; i < b.N; i++ {
        req := &BatchProcessRequest{
            Files: files,
            Concurrency: 5,
        }
        
        _, err := processor.BatchProcessImages(context.Background(), req)
        if err != nil {
            b.Fatal(err)
        }
    }
}
```

é€™å€‹è¨­è¨ˆæ–‡ä»¶æä¾›äº†å®Œæ•´çš„æŠ€è¡“æ¶æ§‹ï¼ŒåŒ…æ‹¬ï¼š

1. **æœ€å°ä¾µå…¥æ€§æ“´å±•**: ä½¿ç”¨ç¾æœ‰ UnifiedChunk çš„ metadata æ¬„ä½
2. **å¯æ’æ‹”å„²å­˜**: æ”¯æ´å¤šç¨®å„²å­˜å¾Œç«¯çš„æŠ½è±¡ä»‹é¢
3. **å®Œæ•´çš„åœ–ç‰‡è™•ç†æµç¨‹**: ä¸Šå‚³ã€åˆ†æã€å‘é‡åŒ–ã€ç´¢å¼•
4. **å¼·å¤§çš„å¤šæ¨¡æ…‹æœå°‹**: æ–‡å­—ã€åœ–ç‰‡ã€æ··åˆæœå°‹
5. **æ¨™æº– MCP æ•´åˆ**: å®Œå…¨ç¬¦åˆ MCP å”è­°çš„å·¥å…·å®šç¾©
6. **å…¨é¢çš„éŒ¯èª¤è™•ç†**: é‡è©¦ã€é™ç´šã€éƒ¨åˆ†æˆåŠŸæ©Ÿåˆ¶
7. **å®Œæ•´çš„æ¸¬è©¦ç­–ç•¥**: å–®å…ƒã€æ•´åˆã€æ•ˆèƒ½æ¸¬è©¦

æ¥ä¸‹ä¾†å¯ä»¥é€²å…¥å¯¦ä½œéšæ®µï¼ŒæŒ‰ç…§è¨­è¨ˆé€æ­¥å¯¦ç¾å„å€‹çµ„ä»¶ã€‚